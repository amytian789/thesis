\section{Numerical data analysis}
\label{sec:intro:numerical}

An important application of our system is in dependencies among financial equities. Determining the relationship among various stocks is especially useful when managing portfolios. One such consideration is a ``buy and hold'' tactic. This strategy is especially useful when transaction costs are high. Building a portfolio in such an environment means taking hedging into account so as to minimize the impact of bears on portfolio returns. Negatively correlated stocks hedge each other; as one goes down, the other goes up; in an ideal world, this results in zero net loss. The concept of sparsity is important once again. The analyst is looking to find negatively correlated instruments, but if the model is improperly selected, there may be too many connected variables. This makes interpretability and, ultimately, selection difficult as portfolio construction is performed with a fixed amount of capital.

In a world with low transaction costs, however, there is more to be gained (less to be lost, alternatively) by frequently rebalancing the portfolio rather than holding. A way to hedge the portfolio when rebalancing would be to select relatively independent assets; with perfect independence, rebalancing gains become a function of the volatility of the stocks rather than prices or other factors~\cite{liuh2016}. This is extremely important because putting in a trade for buy or sell an asset can move the market, leading to unexpected price swings. By selecting independent stocks, the analyst is able to minimize the price risk associated with rebalancing. Identification of independent stocks is another form of model selection; the goal is to select the proper model such that relationships (and in the case of stocks, the independence) among variables are easily seen. While a numerical model can certainly be fitted, it is still important to have a visualization tool to validate the results or risk losing millions of dollars.

Another financial application is the creation of a predictive model for a certain company's stock. This case is more in line with the definition of model selection noted earlier as the analyst is looking for dependence rather than independence. The analyst would like to filter out the independent assets $X$ only to leave those which can explain the response in stock $Y$. This correlation can be positive or negative, and it can be a useful aid in trading as the predictive model, if it is to be believed, can signal price swings to come which opens up arbitrage opportunities. All of these methodologies can be boiled down to this one problem: determining the relationship among different stocks. This is not a trivial task, and there are a multitude of existing numerical approaches to quantify the relationships among different assets. 






\subsection{Existing methods}
\label{sec:intro:numerical:existingmethods}

Equity market datasets are often large; when searching the space for correlated variables, we would like search through as many stocks as possible in order to be thorough and achieve the best possible portfolio. While there are many ways to quantify the relationship between different variables, we focus on correlation graphs and graphical models. A single correlation can be thought of as a regression of the response variable against only one observed variable; it is a ``local'' property because it compares the behavior of only two random variables. On the other hand, a single link in a graphical model can be thought of as a regression of the response variable against all variables in the space. It is more nuanced than that, but the idea is that a graphical model has a “global” property because it takes all of the other variables into account. Although it may seem simple to numerically quantify the dependencies with correlation as conditional dependencies are less intuitive to compute, correlations tend to fall short of the desired result due to the property of transitivity.

\subsubsection{Correlation}

Correlation graphs are one way to discover the dependency structure among the different stocks. Let $G=(V,E)$ be an undirected graph with vertices $V_{1},...,V_{d}$ \textasciitilde $P$ (a $d$-dimensional distribution) and edges $E_ij\in\{0,1\}$. We set $E_{i,j}=1$ when there is an edge between $V_i$ and $V_j$, and 0 otherwise. An edge is drawn between $V_i$ and $V_j$ iff the two random variables are correlated. This graph can be drawn from a correlation matrix $\sum$ with the following heuristic:\\

\begin{algorithm}
	If $\sum_{i,j}=corr(V_1,V_2)>p$, draw edge $E_{i,j}$ where $p$ is the $p$-value for the desired confidence level
\end{algorithm}

As mentioned earlier, we would like to find stocks that are as uncorrelated as possible in order to achieve the most robust portfolio. A common methodology to do this is to forego plotting entirely and numerically compute the correlation matrix then create a graph from that. By construction, the correlation matrix applies the same correlation computation to each set of observed and response variables. Correlation coefficients are rather limited and have their own flaws, so no coefficient is a “one size fits all” solution. For example, some variables could share a linear relationship with the response (ideal for a Pearson correlation) while others may not. While on the subject of the Pearson correlation, it should be noted that correlation graphs are still interesting because two variables that have a correlation coefficient near 0 may not necessarily be uncorrelated. A visualization tool can reveal this by showing outliers or patterns in the data that the analyst wasn't expecting (Section~\ref{sec:intro:me2}). Thus, the analyst needs to perform a visual check of the resulting correlation matrix rather than blinding accepting the results. This is important for improving accountability, as well, but it is a more difficult task than one might believe. In order to confirm that the coefficient used applies to each potential relationship, the analyst must plot all possible sets of data, which we have already established as computationally infeasible and tedious to sort through in high dimensions.

Furthermore, the result itself can be uninformative. Consider the property of transitivity, which states that if $X$ is correlated to $Y$, and $Y$ to $Z$, then $X$ is also correlated to $Z$. Although correlation is not always transitive, situations where the correlation is close to 1 or 0, then the transitivity of correlation can be recovered and observed in the relevant data~\cite{tao2014} Furthermore, correlation is a "local" property because it compares the behavior of only two random variables and ignores the rest of the data space, which may lead to an increasing amount of ``false positives''. Let us assume that the universe consists of Apple, Google, and Silicone (a manufacturer providing chips to both Apple and Google) stock. Suppose an analyst wants to model Google stock. Apple stock moves with Silicone stock as they depend on them for their chips. Similarly, Google stock (unbeknownst to the analyst) also moves with Silicone stock but not with Apple stock. The correlation between observed prices of Google and Apple stock will clearly and erroneously be positive without considering the way the stocks are connected to the other observed variable (Silicone stock). Given that correlation tends to be transitive, a correlation graph can have too many edges. This goes against the concept of ``sparsity''  and clutters the resulting space of observation variables that explain the response variable for the user. In the end, the analyst is left with an uninformative and unaccountable numerical solution.

\subsubsection{Regression and graphical models}

Graphical models alleviate some of the problems associated with correlation graphs, but they have their own set of problems, as well. Let G=(V,E) be an undirected graph with vertices $V_1,...,V_d$ \textasciitilde $P$ (a $d$-dimensional distribution) and edges $E_{i,j}\in\{0,1\}$. We set $E_{i,j}=1$ when there is an edge between $V_i$ and $V_j$, and 0 otherwise. Do not draw an edge between $V_i$ and $V_j$ iff $V_i \perp V_j$ given $V_k$ where $k\in\{1,...,d\}$ \textbackslash $\{i,j\}$. In other words, do not draw an edge if
$$P(V_i,V_j|V_k)=P(V_i|V_k)P(V_j|V_k)$$

This is known as a graphical model. The drawback is the difficulty in empirically computing conditional distributions and the problems associated with fitting distributions to real data. While there are simplifications that can be made for plotting (Section \ref{sec:visualizer:scatterplot:conditional}), the solution is not always so clear. However, the conditional independence of graphical models is more of a global property than correlation is because, for every pair of variables, it conditions on all the remaining variables. Returning to the universe of Google, Apple, and Silicone stocks, conditioning Google on Silicone and Apple on Silicone makes the relationship between the two clearly uncorrelated. Thus, although conditional independence tends to be more difficult to determine, it will tend to give a sparser network that is more interpretable for the analyst. The search through the rest of the data space is akin to the way regressions are fitted.

There are many ways to numerically perform model selection, and regression is the most common. In low-dimensional settings (where there are more samples than explanatory variables), the most common way is to fit a least-squares linear regression and perform a hypothesis test on each coefficient. The F-test is another useful tool for numerically informing the user if a regression model with more variables has significantly more explanatory power over a nested regression model. There are also ways to perform regression and model selection simultaneously. The most common estimator is the Lasso, the Least Absolute Shrinkage and Selection Operator (Tibshirani 1996). The drawback to all these methods is that their theoretical properties tend to either be asymptotic or reliant on assumptions. The former is unsatisfactory since datasets in practice are typically of a fixed size, far from the number of samples to achieve desirable properties analogous to when the number of samples goes to infinity. The latter is unsatisfactory because these assumptions are typically hard to verify or provide convincing justifications of.

Analysts may choose to use correlation over graphical models or vice versa as each has its own niche to fill. It has been shown that the rebalancing method, which leverages independent stocks and is more akin to graphical models, outperforms the ``buy and hold'' method, which leverages negatively correlated variables and naturally lends itself to the correlation approach~\cite{liuh2016}. Due to the nature of our financial application, we choose to utilize graphical models in our analysis of the data, but it is important to understand that both methodologies have the same need for a program that makes high dimensional visualization simple. This allows the analyst to make an informed decision on whether to confirm or reject the numerical result and improves decision-making in the financial industry.




\subsection{Data collection}
\label{sec:intro:numerical:datacollection}

((I will explain how I collected the stock data (end-of-day historical prices for a thousand stocks over the last decade). I will also explain the data cleaning (to get rid of the dependency on time). This will be done by fitting a regression to the values and using the residuals as the new dataset. This makes it appear as if it is independent draws from a sample (perhaps this can be proved more rigorously).))




\subsection{Analysis with existing tools}
\label{sec:intro:numerical:analysis}

((Analogous to before, I will perform a full analysis without ever plotting the data. The goal is to find independent stocks for portfolio rebalancing. I will use a pre-made graphical model in order to fit the data numerically (as this is not the focus of the thesis – this can be thought of as another step of “data processing” for the visualization system input). For simplicity (and since there are known, clear trends that we can expect of the conditional plots), I will probably use (and explain why I decided to use) the Gaussian graphical model.))