\section{Correlation graphs}
\label{sec:intro:correlation}

Equity market datasets are often large; when searching the space for correlated variables, we would like search through as many stocks as possible in order to be thorough and achieve the best possible portfolio. While there are many ways to quantify the relationship between different variables, we focus on correlation graphs and graphical models. A single correlation can be thought of as a regression of the response variable against only one observed variable; it is a ``local'' property because it compares the behavior of only two random variables. On the other hand, a single link in a graphical model can be thought of as a regression of the response variable against all variables in the space. It is more nuanced than that, but the idea is that a graphical model has a “global” property because it takes all of the other variables into account. Although it may seem simple to numerically quantify the dependencies with correlation as conditional dependencies are less intuitive to compute, correlations tend to fall short of the desired result due to the property of transitivity.

\subsection{Correlation}

Correlation graphs are one way to discover the dependency structure among the different stocks. Let $G=(V,E)$ be an undirected graph with vertices $V_{1},...,V_{d}$ \textasciitilde $P$ (a $d$-dimensional distribution) and edges $E_ij\in\{0,1\}$. We set $E_{i,j}=1$ when there is an edge between $V_i$ and $V_j$, and 0 otherwise. An edge is drawn between $V_i$ and $V_j$ iff the two random variables are correlated. This graph can be drawn from a correlation matrix $\sum$ with the following heuristic:\\

\begin{algorithm}
	If $\sum_{i,j}=corr(V_1,V_2)>p$, draw edge $E_{i,j}$ where $p$ is the $p$-value for the desired confidence level
\end{algorithm}

As mentioned earlier, we would like to find stocks that are as uncorrelated as possible in order to achieve the most robust portfolio. A common methodology to do this is to forego plotting entirely and numerically compute the correlation matrix then create a graph from that. By construction, the correlation matrix applies the same correlation computation to each set of observed and response variables. Correlation coefficients are rather limited and have their own flaws, so no coefficient is a “one size fits all” solution. For example, some variables could share a linear relationship with the response (ideal for a Pearson correlation) while others may not. While on the subject of the Pearson correlation, it should be noted that correlation graphs are still interesting because two variables that have a correlation coefficient near 0 may not necessarily be uncorrelated. A visualization tool can reveal this by showing outliers or patterns in the data that the analyst wasn't expecting (Section~\ref{sec:intro:me2}). Thus, the analyst needs to perform a visual check of the resulting correlation matrix rather than blinding accepting the results. This is important for improving accountability, as well, but it is a more difficult task than one might believe. In order to confirm that the coefficient used applies to each potential relationship, the analyst must plot all possible sets of data, which we have already established as computationally infeasible and tedious to sort through in high dimensions.

Furthermore, the result itself can be uninformative. Consider the property of transitivity, which states that if $X$ is correlated to $Y$, and $Y$ to $Z$, then $X$ is also correlated to $Z$. Although correlation is not always transitive, situations where the correlation is close to 1 or 0, then the transitivity of correlation can be recovered and observed in the relevant data~\cite{tao2014} Furthermore, correlation is a "local" property because it compares the behavior of only two random variables and ignores the rest of the data space, which may lead to an increasing amount of ``false positives''. Let us assume that the universe consists of Apple, Google, and Silicone (a manufacturer providing chips to both Apple and Google) stock. Suppose an analyst wants to model Google stock. Apple stock moves with Silicone stock as they depend on them for their chips. Similarly, Google stock (unbeknownst to the analyst) also moves with Silicone stock but not with Apple stock. The correlation between observed prices of Google and Apple stock will clearly and erroneously be positive without considering the way the stocks are connected to the other observed variable (Silicone stock). Given that correlation tends to be transitive, a correlation graph can have too many edges. This goes against the concept of ``sparsity''  and clutters the resulting space of observation variables that explain the response variable for the user. In the end, the analyst is left with an uninformative and unaccountable numerical solution.