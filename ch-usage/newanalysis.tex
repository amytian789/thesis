\section{Procedure}
\label{sec:usage:newanalysis}

Now the issue is that there are many numerical correlation graphs which may be 
computed with different correlation coefficients; given the large data set, it 
is unclear which metric might be the best one. This is where the visualization 
system comes in and ties everything together. By learning the user's interests 
and automatically labeling all pairwise scatter plots as ``visually 
correlated'' or ``not visually correlated'', the 
VS outputs a visual correlation graph that may be used as a ``sanity check'' 
against the various numerical correlation graphs and provide a guide for 
selecting the most visually intuitive numerical correlation graph.

Let $X$ be a $n\times d$ data matrix where there are $d$ observations of $n$ 
variables. Specifically, $n = 43$ and $d = 2050$ in the healthcare data set. 
Recall that the data used for active learning classification by the 
VS is actually 
composed of all observations of characteristic features (as described in 
Section~\ref{sec:visualizer:scatterplot:features}) for all ${n\choose 2} = 
n(n-1)/2 = 903$ pairwise scatter plots of the $n=43$ variables from the actual 
healthcare data set $X$. The final procedure is as follows:

\tablespacing
\begin{enumerate}
	\item With threshold $t = 0.15$, create four different numerical 
	correlation graphs $\hat{G}^{i,\text{num}}=(V,E)$ where $|V| = n$ for all 
	$i\in \{1,...,4\}$, one for each correlation coefficient described in 
	Section~\ref{sec:intro:correlation} (Pearson's, Spearman's, Kendall's, and 
	distance correlation).
	
	\item Run the VS on the same data set. Stage 1 of the system utilizes the 
	active learning algorithm selected in Chapter~\ref{ch:al} (uncertainty 
	sampling with a budget of $iter = 15$) to learn what is 
	``visually correlated'' and ``not visually correlated.'' Stage 2 of the 
	system uses the resulting classifier (built from a random forest 
	classification model) to iterate through all unlabeled pairwise scatter 
	plots and returns a visual graph $\hat{G}=(V,E)$ built from the following 
	heuristic:

\begin{algorithm}
	$E_{i,j} = 1$ for $i\neq j$ if the pairwise scatter plot of $(X_i, X_j)$ 
	is ``visually correlated'' (as determined by the learned stage 2 labels)
\end{algorithm}

	\item Utilize the graph comparison methodology described in 
	Chapter~\ref{ch:gc} to find the difference of each pair 
	$(\hat{G},\hat{G}^{i,\text{num}})$ for all $i \in \{1,...,4\}$. Select 
	numerical graph $\hat{G}^*$ such 
	that $\text{diff}(\hat{G},\hat{G}^*) \leq 
	\text{diff}(\hat{G},\hat{G}^{i,\text{num}})$ for all $i\in 
	\{1,...,4\}$. The numerical correlation graph $\hat{G}^*$ is then the graph 
	which best matches the visual interpretation of the relationships among the 
	data set's variables.
	
	\item Using the stock selection procedure described in 
	Section~\ref{sec:usage:stockselection}, create $P^i$, a portfolio of $k = 
	5$ stocks, from the numerical correlation graph $\hat{G}^{i,\text{num}}$ 
	for all $i \in \{1,...,4\}$ (including portfolio 
	$P^*$ from the numerical graph selected as $\hat{G}^*$). Each selected 
	stock holds equal weight in the portfolio.
	
	\item Observe the ``buy and hold'' performance of each portfolio until 2014.
\end{enumerate}
\bodyspacing

In a standard application, it might be sufficient to simply select $P^*$ from 
$\hat{G}^*$, record the 
yearly returns, and then be done. However, because the purpose of this chapter 
is to demonstrate the usage and viability of the VS in aiding with the 
selection of an appropriate numerical model (given a data set and some 
application), it is necessary to compare the results of all options to each 
other. 
It is natural to expect that the portfolio $P^*$ will perform the best 
as that is the purpose of the visualization system, after all. 
By comparing the results of $P^*$ against the results of the portfolios created 
from the other numerical correlation graphs, we may determine just how well the 
system captures the user's intuition of visual dependence (which is likely to 
be far more complex than a single metric can capture).
The final code for the application procedure may be found in 
Appendix~\ref{sec:appendicies:usage:newanalysis}.